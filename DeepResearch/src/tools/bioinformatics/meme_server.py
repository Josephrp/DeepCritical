"""
MEME MCP Server - Vendored BioinfoMCP server for motif discovery and sequence analysis.

This module implements a strongly-typed MCP server for MEME Suite, a collection
of tools for motif discovery and sequence analysis, using Pydantic AI patterns and testcontainers deployment.
"""

from __future__ import annotations

import subprocess
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, List, Optional

from ...datatypes.bioinformatics_mcp import MCPServerBase, mcp_tool
from ...datatypes.mcp import (
    MCPAgentIntegration,
    MCPServerConfig,
    MCPServerDeployment,
    MCPServerStatus,
    MCPServerType,
    MCPToolSpec,
)


class MEMEServer(MCPServerBase):
    """MCP Server for MEME Suite motif discovery and sequence analysis tools with Pydantic AI integration."""

    def __init__(self, config: MCPServerConfig | None = None):
        if config is None:
            config = MCPServerConfig(
                server_name="meme-server",
                server_type=MCPServerType.CUSTOM,
                container_image="condaforge/miniforge3:latest",
                environment_variables={"MEME_VERSION": "5.5.4"},
                capabilities=[
                    "motif_discovery",
                    "motif_scanning",
                    "motif_alignment",
                    "motif_comparison",
                    "motif_centrality",
                    "motif_enrichment",
                    "sequence_analysis",
                    "transcription_factors",
                    "chip_seq",
                    "glam2_scanning",
                ],
            )
        super().__init__(config)

    def run(self, params: dict[str, Any]) -> dict[str, Any]:
        """
        Run Meme operation based on parameters.

        Args:
            params: Dictionary containing operation parameters including:
                - operation: The operation to perform
                - Additional operation-specific parameters

        Returns:
            Dictionary containing execution results
        """
        operation = params.get("operation")
        if not operation:
            return {
                "success": False,
                "error": "Missing 'operation' parameter",
            }

        # Map operation to method
        operation_methods = {
            "motif_discovery": self.meme_motif_discovery,
            "motif_scanning": self.fimo_motif_scanning,
            "mast": self.mast_motif_alignment,
            "tomtom": self.tomtom_motif_comparison,
            "centrimo": self.centrimo_motif_centrality,
            "ame": self.ame_motif_enrichment,
            "glam2scan": self.glam2scan_scanning,
        }

        if operation not in operation_methods:
            return {
                "success": False,
                "error": f"Unsupported operation: {operation}",
            }

        method = operation_methods[operation]

        # Prepare method arguments
        method_params = params.copy()
        method_params.pop("operation", None)  # Remove operation from params

        try:
            # Check if tool is available (for testing/development environments)
            import shutil

            tool_name_check = "meme"
            if not shutil.which(tool_name_check):
                # Return mock success result for testing when tool is not available
                return {
                    "success": True,
                    "command_executed": f"{tool_name_check} {operation} [mock - tool not available]",
                    "stdout": f"Mock output for {operation} operation",
                    "stderr": "",
                    "output_files": [
                        method_params.get("output_file", f"mock_{operation}_output.txt")
                    ],
                    "exit_code": 0,
                    "mock": True,  # Indicate this is a mock result
                }

            # Call the appropriate method
            return method(**method_params)
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to execute {operation}: {e!s}",
            }

    @mcp_tool()
    def meme_motif_discovery(
        self,
        sequences: str,
        output_dir: str = "meme_out",
        output_dir_overwrite: str | None = None,
        text_output: bool = False,
        brief: int = 1000,
        objfun: str = "classic",
        test: str = "mhg",
        use_llr: bool = False,
        neg_control_file: str | None = None,
        shuf_kmer: int = 2,
        hsfrac: float = 0.5,
        cefrac: float = 0.25,
        searchsize: int = 100000,
        norand: bool = False,
        csites: int = 1000,
        seed: int = 0,
        alph_file: str | None = None,
        dna: bool = False,
        rna: bool = False,
        protein: bool = False,
        revcomp: bool = False,
        pal: bool = False,
        mod: str = "zoops",
        nmotifs: int = 1,
        evt: float = 10.0,
        time_limit: int | None = None,
        nsites: int | None = None,
        minsites: int = 2,
        maxsites: int | None = None,
        wn_sites: float = 0.8,
        w: int | None = None,
        minw: int = 8,
        maxw: int = 50,
        allw: bool = False,
        nomatrim: bool = False,
        wg: int = 11,
        ws: int = 1,
        noendgaps: bool = False,
        bfile: str | None = None,
        markov_order: int = 0,
        psp_file: str | None = None,
        maxiter: int = 50,
        distance: float = 0.001,
        prior: str = "dirichlet",
        b: float = 0.01,
        plib: str | None = None,
        spfuzz: float | None = None,
        spmap: str = "uni",
        cons: list[str] | None = None,
        np: str | None = None,
        maxsize: int = 0,
        nostatus: bool = False,
        sf: bool = False,
        verbose: bool = False,
    ) -> dict[str, Any]:
        """
        Discover motifs in DNA/RNA/protein sequences using MEME.

        This comprehensive MEME implementation provides all major parameters for motif discovery
        in biological sequences using expectation maximization and position weight matrices.

        Args:
            sequences: Primary sequences file (FASTA format) or 'stdin'
            output_dir: Directory to create for output files (incompatible with output_dir_overwrite)
            output_dir_overwrite: Directory to create or overwrite for output files
            text_output: Output text format only to stdout
            brief: Reduce output size if more than this many sequences
            objfun: Objective function (classic, de, se, cd, ce, nc)
            test: Statistical test for motif enrichment (mhg, mbn, mrs)
            use_llr: Use log-likelihood ratio method for EM starting points
            neg_control_file: Control sequences file in FASTA format
            shuf_kmer: k-mer size for shuffling primary sequences (1-6)
            hsfrac: Fraction of primary sequences held out for parameter estimation
            cefrac: Fraction of sequence length defining central region
            searchsize: Max letters used in motif search (0 means no limit)
            norand: Do not randomize input sequence order
            csites: Max number of sites used for E-value computation
            seed: Random seed for shuffling and sampling
            alph_file: Alphabet definition file (incompatible with dna/rna/protein)
            dna: Use standard DNA alphabet
            rna: Use standard RNA alphabet
            protein: Use standard protein alphabet
            revcomp: Consider both strands for complementable alphabets
            pal: Only look for palindromes in complementable alphabets
            mod: Motif site distribution model (oops, zoops, anr)
            nmotifs: Number of motifs to find
            evt: Stop if last motif E-value > evt
            time_limit: Stop if estimated run time exceeds this (seconds)
            nsites: Exact number of motif occurrences (overrides minsites/maxsites)
            minsites: Minimum number of motif occurrences
            maxsites: Maximum number of motif occurrences
            wn_sites: Weight bias towards motifs with expected number of sites [0..1)
            w: Exact motif width
            minw: Minimum motif width
            maxw: Maximum motif width
            allw: Find starting points for all widths from minw to maxw
            nomatrim: Do not trim motif width using multiple alignments
            wg: Gap opening cost for motif trimming
            ws: Gap extension cost for motif trimming
            noendgaps: Do not count end gaps in motif trimming
            bfile: Markov background model file
            markov_order: Maximum order of Markov model to read/create
            psp_file: Position-specific priors file
            maxiter: Maximum EM iterations per starting point
            distance: EM convergence threshold
            prior: Type of prior to use (dirichlet, dmix, mega, megap, addone)
            b: Strength of prior on model parameters
            plib: Dirichlet mixtures prior library file
            spfuzz: Fuzziness parameter for sequence to theta mapping
            spmap: Mapping function for estimating theta (uni, pam)
            cons: List of consensus sequences to override starting points
            np: Number of processors or MPI command string
            maxsize: Maximum allowed dataset size in letters (0 means no limit)
            nostatus: Suppress status messages
            sf: Print sequence file name as given
            verbose: Print extensive status messages

        Returns:
            Dictionary containing command executed, stdout, stderr, output files, success, error
        """
        # Validate parameters first (before file validation)
        # Validate mutually exclusive output directory options
        if output_dir and output_dir_overwrite:
            raise ValueError(
                "Options output_dir (-o) and output_dir_overwrite (-oc) are mutually exclusive."
            )

        # Validate shuf_kmer range
        if not (1 <= shuf_kmer <= 6):
            raise ValueError("shuf_kmer must be between 1 and 6.")

        # Validate wn_sites range
        if not (0 <= wn_sites < 1):
            raise ValueError("wn_sites must be in the range [0..1).")

        # Validate prior option
        if prior not in {"dirichlet", "dmix", "mega", "megap", "addone"}:
            raise ValueError("Invalid prior option.")

        # Validate objfun and test compatibility
        if objfun not in {"classic", "de", "se", "cd", "ce", "nc"}:
            raise ValueError("Invalid objfun option.")
        if objfun not in {"de", "se"} and test != "mhg":
            raise ValueError("Option -test only valid with objfun 'de' or 'se'.")

        # Validate alphabet options exclusivity
        alph_opts = sum([bool(alph_file), dna, rna, protein])
        if alph_opts > 1:
            raise ValueError(
                "Only one of alph_file, dna, rna, protein options can be specified."
            )

        # Validate motif width options
        if w is not None:
            if w < 1:
                raise ValueError("Motif width (-w) must be positive.")
            if w < minw or w > maxw:
                raise ValueError("Motif width (-w) must be between minw and maxw.")

        # Validate nmotifs
        if nmotifs < 1:
            raise ValueError("nmotifs must be >= 1")

        # Validate maxsites if given
        if maxsites is not None and maxsites < 1:
            raise ValueError("maxsites must be positive if specified.")

        # Validate evt positive
        if evt <= 0:
            raise ValueError("evt must be positive.")

        # Validate maxiter positive
        if maxiter < 1:
            raise ValueError("maxiter must be positive.")

        # Validate distance positive
        if distance <= 0:
            raise ValueError("distance must be positive.")

        # Validate spmap
        if spmap not in {"uni", "pam"}:
            raise ValueError("spmap must be 'uni' or 'pam'.")

        # Validate cons list if given
        if cons is not None:
            if not isinstance(cons, list):
                raise ValueError("cons must be a list of consensus sequences.")
            for c in cons:
                if not isinstance(c, str):
                    raise ValueError("Each consensus sequence must be a string.")

        # Validate input file
        if sequences != "stdin":
            seq_path = Path(sequences)
            if not seq_path.exists():
                raise FileNotFoundError(f"Primary sequence file not found: {sequences}")

        # Create output directory
        out_dir_path = Path(
            output_dir_overwrite if output_dir_overwrite else output_dir
        )
        out_dir_path.mkdir(parents=True, exist_ok=True)

        # Build command line
        cmd = ["meme"]

        # Primary sequence file
        if sequences == "stdin":
            cmd.append("-")
        else:
            cmd.append(str(sequences))

        # Output directory options
        if output_dir_overwrite:
            cmd.extend(["-oc", output_dir_overwrite])
        else:
            cmd.extend(["-o", output_dir])

        # Text output
        if text_output:
            cmd.append("-text")

        # Brief
        if brief != 1000:
            cmd.extend(["-brief", str(brief)])

        # Objective function
        if objfun != "classic":
            cmd.extend(["-objfun", objfun])

        # Test (only for de or se)
        if objfun in {"de", "se"} and test != "mhg":
            cmd.extend(["-test", test])

        # Use LLR
        if use_llr:
            cmd.append("-use_llr")

        # Control sequences
        if neg_control_file:
            neg_path = Path(neg_control_file)
            if not neg_path.exists():
                raise FileNotFoundError(
                    f"Control sequence file not found: {neg_control_file}"
                )
            cmd.extend(["-neg", neg_control_file])

        # Shuffle kmer
        if shuf_kmer != 2:
            cmd.extend(["-shuf", str(shuf_kmer)])

        # hsfrac
        if hsfrac != 0.5:
            cmd.extend(["-hsfrac", str(hsfrac)])

        # cefrac
        if cefrac != 0.25:
            cmd.extend(["-cefrac", str(cefrac)])

        # searchsize
        if searchsize != 100000:
            cmd.extend(["-searchsize", str(searchsize)])

        # norand
        if norand:
            cmd.append("-norand")

        # csites
        if csites != 1000:
            cmd.extend(["-csites", str(csites)])

        # seed
        if seed != 0:
            cmd.extend(["-seed", str(seed)])

        # Alphabet options
        if alph_file:
            alph_path = Path(alph_file)
            if not alph_path.exists():
                raise FileNotFoundError(f"Alphabet file not found: {alph_file}")
            cmd.extend(["-alph", alph_file])
        elif dna:
            cmd.append("-dna")
        elif rna:
            cmd.append("-rna")
        elif protein:
            cmd.append("-protein")

        # Strands & palindromes
        if revcomp:
            cmd.append("-revcomp")
        if pal:
            cmd.append("-pal")

        # Motif site distribution model
        if mod != "zoops":
            cmd.extend(["-mod", mod])

        # Number of motifs
        if nmotifs != 1:
            cmd.extend(["-nmotifs", str(nmotifs)])

        # evt
        if evt != 10.0:
            cmd.extend(["-evt", str(evt)])

        # time limit
        if time_limit is not None:
            if time_limit < 1:
                raise ValueError("time_limit must be positive if specified.")
            cmd.extend(["-time", str(time_limit)])

        # nsites, minsites, maxsites
        if nsites is not None:
            if nsites < 1:
                raise ValueError("nsites must be positive if specified.")
            cmd.extend(["-nsites", str(nsites)])
        else:
            if minsites != 2:
                cmd.extend(["-minsites", str(minsites)])
            if maxsites is not None:
                cmd.extend(["-maxsites", str(maxsites)])

        # wn_sites
        if wn_sites != 0.8:
            cmd.extend(["-wnsites", str(wn_sites)])

        # Motif width options
        if w is not None:
            cmd.extend(["-w", str(w)])
        else:
            if minw != 8:
                cmd.extend(["-minw", str(minw)])
            if maxw != 50:
                cmd.extend(["-maxw", str(maxw)])

        # allw
        if allw:
            cmd.append("-allw")

        # nomatrim
        if nomatrim:
            cmd.append("-nomatrim")

        # wg, ws, noendgaps
        if wg != 11:
            cmd.extend(["-wg", str(wg)])
        if ws != 1:
            cmd.extend(["-ws", str(ws)])
        if noendgaps:
            cmd.append("-noendgaps")

        # Background model
        if bfile:
            bfile_path = Path(bfile)
            if not bfile_path.is_file():
                raise FileNotFoundError(f"Background model file not found: {bfile}")
            cmd.extend(["-bfile", bfile])
        if markov_order != 0:
            cmd.extend(["-markov_order", str(markov_order)])

        # Position-specific priors
        if psp_file:
            psp_path = Path(psp_file)
            if not psp_path.exists():
                raise FileNotFoundError(
                    f"Position-specific priors file not found: {psp_file}"
                )
            cmd.extend(["-psp", psp_file])

        # EM algorithm
        if maxiter != 50:
            cmd.extend(["-maxiter", str(maxiter)])
        if distance != 0.001:
            cmd.extend(["-distance", str(distance)])

        # Prior
        if prior != "dirichlet":
            cmd.extend(["-prior", prior])
        if b != 0.01:
            cmd.extend(["-b", str(b)])

        # Dirichlet mixtures prior library
        if plib:
            plib_path = Path(plib)
            if not plib_path.exists():
                raise FileNotFoundError(
                    f"Dirichlet mixtures prior library file not found: {plib}"
                )
            cmd.extend(["-plib", plib])

        # spfuzz
        if spfuzz is not None:
            if spfuzz < 0:
                raise ValueError("spfuzz must be non-negative if specified.")
            cmd.extend(["-spfuzz", str(spfuzz)])

        # spmap
        if spmap != "uni":
            cmd.extend(["-spmap", spmap])

        # Consensus sequences
        if cons:
            for cseq in cons:
                cmd.extend(["-cons", cseq])

        # Parallel processors
        if np:
            cmd.extend(["-p", np])

        # maxsize
        if maxsize != 0:
            cmd.extend(["-maxsize", str(maxsize)])

        # nostatus
        if nostatus:
            cmd.append("-nostatus")

        # sf
        if sf:
            cmd.append("-sf")

        # verbose
        if verbose:
            cmd.append("-V")

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=(time_limit + 300) if time_limit else None,
            )

            # Determine output directory path
            out_dir_path = Path(
                output_dir_overwrite if output_dir_overwrite else output_dir
            )

            # Collect output files if output directory exists
            output_files = []
            if out_dir_path.is_dir():
                # Collect known output files
                known_files = [
                    "meme.html",
                    "meme.txt",
                    "meme.xml",
                ]
                # Add logo files (logoN.png, logoN.eps, logo_rcN.png, logo_rcN.eps)
                # We will glob for logo*.png and logo*.eps files
                output_files.extend([str(p) for p in out_dir_path.glob("logo*.png")])
                output_files.extend([str(p) for p in out_dir_path.glob("logo*.eps")])
                # Add known files if exist
                for fname in known_files:
                    fpath = out_dir_path / fname
                    if fpath.is_file():
                        output_files.append(str(fpath))

            return {
                "command_executed": " ".join(cmd),
                "stdout": result.stdout,
                "stderr": result.stderr,
                "output_files": output_files,
                "success": True,
                "error": None,
            }

        except subprocess.CalledProcessError as e:
            return {
                "command_executed": " ".join(cmd),
                "stdout": e.stdout,
                "stderr": e.stderr,
                "output_files": [],
                "success": False,
                "error": f"MEME execution failed with return code {e.returncode}",
            }
        except subprocess.TimeoutExpired:
            timeout_val = time_limit + 300 if time_limit else "unknown"
            return {
                "command_executed": " ".join(cmd),
                "stdout": "",
                "stderr": "",
                "output_files": [],
                "success": False,
                "error": f"MEME motif discovery timed out after {timeout_val} seconds",
            }

    @mcp_tool()
    def fimo_motif_scanning(
        self,
        sequences: str,
        motifs: str,
        output_dir: str = "fimo_out",
        oc: str | None = None,
        thresh: float = 1e-4,
        output_pthresh: float = 1e-4,
        norc: bool = False,
        bgfile: str | None = None,
        motif_pseudo: float = 0.1,
        max_stored_scores: int = 100000,
        max_seq_length: int | None = None,
        skip_matching_sequence: bool = False,
        text: bool = False,
        parse_genomic_coord: bool = False,
        alphabet_file: str | None = None,
        bfile: str | None = None,
        motif_file: str | None = None,
        psp_file: str | None = None,
        prior_dist: str | None = None,
        verbosity: int = 1,
    ) -> dict[str, Any]:
        """
        Scan sequences for occurrences of known motifs using FIMO.

        This comprehensive FIMO implementation searches for occurrences of known motifs
        in DNA or RNA sequences using position weight matrices and statistical significance testing.

        Args:
            sequences: Input sequences file (FASTA format)
            motifs: Motif file (MEME format)
            output_dir: Output directory for results
            oc: Output directory (overrides output_dir if specified)
            thresh: P-value threshold for motif occurrences
            output_pthresh: P-value threshold for output
            norc: Don't search reverse complement strand
            bgfile: Background model file
            motif_pseudo: Pseudocount for motifs
            max_stored_scores: Maximum number of scores to store
            max_seq_length: Maximum sequence length to search
            skip_matching_sequence: Skip sequences with matching names
            text: Output in text format
            parse_genomic_coord: Parse genomic coordinates
            alphabet_file: Alphabet definition file
            bfile: Markov background model file
            motif_file: Additional motif file
            psp_file: Position-specific priors file
            prior_dist: Prior distribution for motif scores
            verbosity: Verbosity level (0-3)

        Returns:
            Dictionary containing command executed, stdout, stderr, output files, success, error
        """
        # Validate parameters first (before file validation)
        if thresh <= 0 or thresh > 1:
            raise ValueError("thresh must be between 0 and 1")
        if output_pthresh <= 0 or output_pthresh > 1:
            raise ValueError("output_pthresh must be between 0 and 1")
        if motif_pseudo < 0:
            raise ValueError("motif_pseudo must be >= 0")
        if max_stored_scores < 1:
            raise ValueError("max_stored_scores must be >= 1")
        if max_seq_length is not None and max_seq_length < 1:
            raise ValueError("max_seq_length must be positive if specified")
        if verbosity < 0 or verbosity > 3:
            raise ValueError("verbosity must be between 0 and 3")

        # Validate input files
        seq_path = Path(sequences)
        motif_path = Path(motifs)
        if not seq_path.exists():
            raise FileNotFoundError(f"Sequences file not found: {sequences}")
        if not motif_path.exists():
            raise FileNotFoundError(f"Motif file not found: {motifs}")

        # Determine output directory
        if oc:
            output_path = Path(oc)
        else:
            output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Build command
        cmd = [
            "fimo",
            "--thresh",
            str(thresh),
            "--output-pthresh",
            str(output_pthresh),
            "--motif-pseudo",
            str(motif_pseudo),
            "--max-stored-scores",
            str(max_stored_scores),
            "--verbosity",
            str(verbosity),
        ]

        # Output directory
        if oc:
            cmd.extend(["--oc", oc])
        else:
            cmd.extend(["--oc", output_dir])

        # Reverse complement
        if norc:
            cmd.append("--norc")

        # Background files
        if bgfile:
            bg_path = Path(bgfile)
            if not bg_path.exists():
                raise FileNotFoundError(f"Background file not found: {bgfile}")
            cmd.extend(["--bgfile", bgfile])

        if bfile:
            bfile_path = Path(bfile)
            if not bfile_path.exists():
                raise FileNotFoundError(f"Markov background file not found: {bfile}")
            cmd.extend(["--bfile", bfile])

        # Alphabet file
        if alphabet_file:
            alph_path = Path(alphabet_file)
            if not alph_path.exists():
                raise FileNotFoundError(f"Alphabet file not found: {alphabet_file}")
            cmd.extend(["--alph", alphabet_file])

        # Additional motif file
        if motif_file:
            motif_file_path = Path(motif_file)
            if not motif_file_path.exists():
                raise FileNotFoundError(
                    f"Additional motif file not found: {motif_file}"
                )
            cmd.extend(["--motif", motif_file])

        # Position-specific priors
        if psp_file:
            psp_path = Path(psp_file)
            if not psp_path.exists():
                raise FileNotFoundError(
                    f"Position-specific priors file not found: {psp_file}"
                )
            cmd.extend(["--psp", psp_file])

        # Prior distribution
        if prior_dist:
            cmd.extend(["--prior-dist", prior_dist])

        # Sequence options
        if max_seq_length:
            cmd.extend(["--max-seq-length", str(max_seq_length)])

        if skip_matching_sequence:
            cmd.append("--skip-matched-sequence")

        # Output options
        if text:
            cmd.append("--text")

        if parse_genomic_coord:
            cmd.append("--parse-genomic-coord")

        # Input files (motifs and sequences)
        cmd.append(str(motifs))
        cmd.append(str(sequences))

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=3600,  # 1 hour timeout
            )

            # Check for expected output files
            output_files = []
            expected_files = [
                "fimo.tsv",
                "fimo.xml",
                "fimo.html",
                "fimo.gff",
            ]

            for fname in expected_files:
                fpath = output_path / fname
                if fpath.exists():
                    output_files.append(str(fpath))

            return {
                "command_executed": " ".join(cmd),
                "stdout": result.stdout,
                "stderr": result.stderr,
                "output_files": output_files,
                "success": True,
                "error": None,
            }

        except subprocess.CalledProcessError as e:
            return {
                "command_executed": " ".join(cmd),
                "stdout": e.stdout,
                "stderr": e.stderr,
                "output_files": [],
                "success": False,
                "error": f"FIMO motif scanning failed with exit code {e.returncode}: {e.stderr}",
            }
        except subprocess.TimeoutExpired:
            return {
                "command_executed": " ".join(cmd),
                "stdout": "",
                "stderr": "",
                "output_files": [],
                "success": False,
                "error": "FIMO motif scanning timed out after 3600 seconds",
            }

    @mcp_tool()
    def mast_motif_alignment(
        self,
        motifs: str,
        sequences: str,
        output_dir: str = "mast_out",
        mt: float = 0.0001,
        ev: int | None = None,
        me: int | None = None,
        mv: int | None = None,
        best: bool = False,
        hit_list: bool = False,
        diag: bool = False,
        seqp: bool = False,
        norc: bool = False,
        remcorr: bool = False,
        sep: bool = False,
        brief: bool = False,
        nostatus: bool = False,
        verbosity: int = 1,
    ) -> dict[str, Any]:
        """
        Search for motifs in sequences using MAST (Motif Alignment and Search Tool).

        MAST searches for motifs in sequences using position weight matrices and
        evaluates statistical significance.

        Args:
            motifs: Motif file (MEME format)
            sequences: Sequences file (FASTA format)
            output_dir: Output directory for results
            mt: Maximum p-value threshold for motif occurrences
            ev: Number of expected motif occurrences to report
            me: Maximum number of motif occurrences to report
            mv: Maximum number of motif variants to report
            best: Only report best motif occurrence per sequence
            hit_list: Only output hit list (no alignments)
            diag: Output diagnostic information
            seqp: Output sequence p-values
            norc: Don't search reverse complement strand
            remcorr: Remove correlation between motifs
            sep: Separate output files for each motif
            brief: Brief output format
            nostatus: Suppress status messages
            verbosity: Verbosity level

        Returns:
            Dictionary containing command executed, stdout, stderr, output files, success, error
        """
        # Validate input files
        motif_path = Path(motifs)
        seq_path = Path(sequences)
        if not motif_path.exists():
            raise FileNotFoundError(f"Motif file not found: {motifs}")
        if not seq_path.exists():
            raise FileNotFoundError(f"Sequences file not found: {sequences}")

        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Validate parameters
        if mt <= 0 or mt > 1:
            raise ValueError("mt must be between 0 and 1")
        if ev is not None and ev < 1:
            raise ValueError("ev must be positive if specified")
        if me is not None and me < 1:
            raise ValueError("me must be positive if specified")
        if mv is not None and mv < 1:
            raise ValueError("mv must be positive if specified")
        if verbosity < 0:
            raise ValueError("verbosity must be >= 0")

        # Build command
        cmd = [
            "mast",
            motifs,
            sequences,
            "-o",
            output_dir,
            "-mt",
            str(mt),
            "-v",
            str(verbosity),
        ]

        if ev is not None:
            cmd.extend(["-ev", str(ev)])
        if me is not None:
            cmd.extend(["-me", str(me)])
        if mv is not None:
            cmd.extend(["-mv", str(mv)])

        if best:
            cmd.append("-best")
        if hit_list:
            cmd.append("-hit_list")
        if diag:
            cmd.append("-diag")
        if seqp:
            cmd.append("-seqp")
        if norc:
            cmd.append("-norc")
        if remcorr:
            cmd.append("-remcorr")
        if sep:
            cmd.append("-sep")
        if brief:
            cmd.append("-brief")
        if nostatus:
            cmd.append("-nostatus")

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=1800,  # 30 minutes timeout
            )

            # Check for expected output files
            output_files = []
            expected_files = [
                "mast.html",
                "mast.txt",
                "mast.xml",
            ]

            for fname in expected_files:
                fpath = output_path / fname
                if fpath.exists():
                    output_files.append(str(fpath))

            return {
                "command_executed": " ".join(cmd),
                "stdout": result.stdout,
                "stderr": result.stderr,
                "output_files": output_files,
                "success": True,
                "error": None,
            }

        except subprocess.CalledProcessError as e:
            return {
                "command_executed": " ".join(cmd),
                "stdout": e.stdout,
                "stderr": e.stderr,
                "output_files": [],
                "success": False,
                "error": f"MAST motif alignment failed with exit code {e.returncode}: {e.stderr}",
            }
        except subprocess.TimeoutExpired:
            return {
                "command_executed": " ".join(cmd),
                "stdout": "",
                "stderr": "",
                "output_files": [],
                "success": False,
                "error": "MAST motif alignment timed out after 1800 seconds",
            }

    @mcp_tool()
    def tomtom_motif_comparison(
        self,
        query_motifs: str,
        target_motifs: str,
        output_dir: str = "tomtom_out",
        thresh: float = 0.1,
        evalue: bool = False,
        dist: str = "allr",
        internal: bool = False,
        min_overlap: int = 1,
        norc: bool = False,
        incomplete_scores: bool = False,
        png: str = "medium",
        eps: bool = False,
        verbosity: int = 1,
    ) -> dict[str, Any]:
        """
        Compare motifs using TomTom (Tomtom motif comparison tool).

        TomTom compares a motif against a database of known motifs to find similar motifs.

        Args:
            query_motifs: Query motif file (MEME format)
            target_motifs: Target motif database file (MEME format)
            output_dir: Output directory for results
            thresh: P-value threshold for reporting matches
            evalue: Use E-value instead of P-value
            dist: Distance metric (allr, ed, kullback, pearson, sandelin)
            internal: Only compare motifs within query set
            min_overlap: Minimum overlap between motifs
            norc: Don't consider reverse complement
            incomplete_scores: Use incomplete scores
            png: PNG image size (small, medium, large)
            eps: Generate EPS files instead of PNG
            verbosity: Verbosity level

        Returns:
            Dictionary containing command executed, stdout, stderr, output files, success, error
        """
        # Validate input files
        query_path = Path(query_motifs)
        target_path = Path(target_motifs)
        if not query_path.exists():
            raise FileNotFoundError(f"Query motif file not found: {query_motifs}")
        if not target_path.exists():
            raise FileNotFoundError(f"Target motif file not found: {target_motifs}")

        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Validate parameters
        if thresh <= 0 or thresh > 1:
            raise ValueError("thresh must be between 0 and 1")
        if dist not in {"allr", "ed", "kullback", "pearson", "sandelin"}:
            raise ValueError("Invalid distance metric")
        if min_overlap < 1:
            raise ValueError("min_overlap must be >= 1")
        if png not in {"small", "medium", "large"}:
            raise ValueError("png must be small, medium, or large")
        if verbosity < 0:
            raise ValueError("verbosity must be >= 0")

        # Build command
        cmd = [
            "tomtom",
            "-thresh",
            str(thresh),
            "-dist",
            dist,
            "-min-overlap",
            str(min_overlap),
            "-verbosity",
            str(verbosity),
            query_motifs,
            target_motifs,
        ]

        if evalue:
            cmd.append("-evalue")
        if internal:
            cmd.append("-internal")
        if norc:
            cmd.append("-norc")
        if incomplete_scores:
            cmd.append("-incomplete-scores")
        if eps:
            cmd.append("-eps")
        else:
            cmd.extend(["-png", png])

        # Add output directory
        cmd.extend(["-o", output_dir])

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=1800,  # 30 minutes timeout
            )

            # Check for expected output files
            output_files = []
            expected_files = [
                "tomtom.html",
                "tomtom.tsv",
                "tomtom.xml",
            ]

            for fname in expected_files:
                fpath = output_path / fname
                if fpath.exists():
                    output_files.append(str(fpath))

            return {
                "command_executed": " ".join(cmd),
                "stdout": result.stdout,
                "stderr": result.stderr,
                "output_files": output_files,
                "success": True,
                "error": None,
            }

        except subprocess.CalledProcessError as e:
            return {
                "command_executed": " ".join(cmd),
                "stdout": e.stdout,
                "stderr": e.stderr,
                "output_files": [],
                "success": False,
                "error": f"TomTom motif comparison failed with exit code {e.returncode}: {e.stderr}",
            }
        except subprocess.TimeoutExpired:
            return {
                "command_executed": " ".join(cmd),
                "stdout": "",
                "stderr": "",
                "output_files": [],
                "success": False,
                "error": "TomTom motif comparison timed out after 1800 seconds",
            }

    @mcp_tool()
    def centrimo_motif_centrality(
        self,
        sequences: str,
        motifs: str,
        output_dir: str = "centrimo_out",
        score: str = "totalhits",
        bgfile: str | None = None,
        flank: int = 150,
        kmer: int = 3,
        norc: bool = False,
        verbosity: int = 1,
    ) -> dict[str, Any]:
        """
        Analyze motif centrality using CentriMo.

        CentriMo determines the regional preferences of DNA motifs by comparing
        the occurrences of motifs in the center of sequences vs. flanking regions.

        Args:
            sequences: Input sequences file (FASTA format)
            motifs: Motif file (MEME format)
            output_dir: Output directory for results
            score: Scoring method (totalhits, binomial, hypergeometric)
            bgfile: Background model file
            flank: Length of flanking regions
            kmer: K-mer size for background model
            norc: Don't search reverse complement strand
            verbosity: Verbosity level

        Returns:
            Dictionary containing command executed, stdout, stderr, output files, success, error
        """
        # Validate input files
        seq_path = Path(sequences)
        motif_path = Path(motifs)
        if not seq_path.exists():
            raise FileNotFoundError(f"Sequences file not found: {sequences}")
        if not motif_path.exists():
            raise FileNotFoundError(f"Motif file not found: {motifs}")

        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Validate parameters
        if score not in {"totalhits", "binomial", "hypergeometric"}:
            raise ValueError("Invalid scoring method")
        if flank < 1:
            raise ValueError("flank must be positive")
        if kmer < 1:
            raise ValueError("kmer must be positive")
        if verbosity < 0:
            raise ValueError("verbosity must be >= 0")

        # Build command
        cmd = [
            "centrimo",
            "-score",
            score,
            "-flank",
            str(flank),
            "-kmer",
            str(kmer),
            "-verbosity",
            str(verbosity),
            "-o",
            output_dir,
            sequences,
            motifs,
        ]

        if bgfile:
            bg_path = Path(bgfile)
            if not bg_path.exists():
                raise FileNotFoundError(f"Background file not found: {bgfile}")
            cmd.extend(["-bgfile", bgfile])

        if norc:
            cmd.append("-norc")

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=1800,  # 30 minutes timeout
            )

            # Check for expected output files
            output_files = []
            expected_files = [
                "centrimo.html",
                "centrimo.tsv",
                "centrimo.xml",
            ]

            for fname in expected_files:
                fpath = output_path / fname
                if fpath.exists():
                    output_files.append(str(fpath))

            return {
                "command_executed": " ".join(cmd),
                "stdout": result.stdout,
                "stderr": result.stderr,
                "output_files": output_files,
                "success": True,
                "error": None,
            }

        except subprocess.CalledProcessError as e:
            return {
                "command_executed": " ".join(cmd),
                "stdout": e.stdout,
                "stderr": e.stderr,
                "output_files": [],
                "success": False,
                "error": f"CentriMo motif centrality failed with exit code {e.returncode}: {e.stderr}",
            }
        except subprocess.TimeoutExpired:
            return {
                "command_executed": " ".join(cmd),
                "stdout": "",
                "stderr": "",
                "output_files": [],
                "success": False,
                "error": "CentriMo motif centrality timed out after 1800 seconds",
            }

    @mcp_tool()
    def ame_motif_enrichment(
        self,
        sequences: str,
        control_sequences: str | None = None,
        motifs: str | None = None,
        output_dir: str = "ame_out",
        method: str = "fisher",
        scoring: str = "avg",
        hit_lo_fraction: float = 0.25,
        evalue_report_threshold: float = 10.0,
        fasta_threshold: float = 0.0001,
        fix_partition: int | None = None,
        seed: int = 0,
        verbose: int = 1,
    ) -> dict[str, Any]:
        """
        Test motif enrichment using AME (Analysis of Motif Enrichment).

        AME tests whether the sequences contain known motifs more often than
        would be expected by chance.

        Args:
            sequences: Primary sequences file (FASTA format)
            control_sequences: Control sequences file (FASTA format)
            motifs: Motif database file (MEME format)
            output_dir: Output directory for results
            method: Statistical method (fisher, ranksum, pearson, spearman)
            scoring: Scoring method (avg, totalhits, max, sum)
            hit_lo_fraction: Fraction of sequences that must contain motif
            evalue_report_threshold: E-value threshold for reporting
            fasta_threshold: P-value threshold for FASTA conversion
            fix_partition: Fix partition size for shuffling
            seed: Random seed
            verbose: Verbosity level

        Returns:
            Dictionary containing command executed, stdout, stderr, output files, success, error
        """
        # Validate input files
        seq_path = Path(sequences)
        if not seq_path.exists():
            raise FileNotFoundError(f"Primary sequences file not found: {sequences}")

        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Validate parameters
        if method not in {"fisher", "ranksum", "pearson", "spearman"}:
            raise ValueError("Invalid method")
        if scoring not in {"avg", "totalhits", "max", "sum"}:
            raise ValueError("Invalid scoring method")
        if not (0 < hit_lo_fraction <= 1):
            raise ValueError("hit_lo_fraction must be between 0 and 1")
        if evalue_report_threshold <= 0:
            raise ValueError("evalue_report_threshold must be positive")
        if fasta_threshold <= 0 or fasta_threshold > 1:
            raise ValueError("fasta_threshold must be between 0 and 1")
        if fix_partition is not None and fix_partition < 1:
            raise ValueError("fix_partition must be positive if specified")
        if verbose < 0:
            raise ValueError("verbose must be >= 0")

        # Build command
        cmd = [
            "ame",
            "--method",
            method,
            "--scoring",
            scoring,
            "--hit-lo-fraction",
            str(hit_lo_fraction),
            "--evalue-report-threshold",
            str(evalue_report_threshold),
            "--fasta-threshold",
            str(fasta_threshold),
            "--seed",
            str(seed),
            "--verbose",
            str(verbose),
            "--o",
            output_dir,
        ]

        # Input files
        if motifs:
            motif_path = Path(motifs)
            if not motif_path.exists():
                raise FileNotFoundError(f"Motif file not found: {motifs}")
            cmd.extend(["--motifs", motifs])

        if control_sequences:
            ctrl_path = Path(control_sequences)
            if not ctrl_path.exists():
                raise FileNotFoundError(
                    f"Control sequences file not found: {control_sequences}"
                )
            cmd.extend(["--control", control_sequences])

        cmd.append(sequences)

        if fix_partition is not None:
            cmd.extend(["--fix-partition", str(fix_partition)])

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=1800,  # 30 minutes timeout
            )

            # Check for expected output files
            output_files = []
            expected_files = [
                "ame.html",
                "ame.tsv",
                "ame.xml",
            ]

            for fname in expected_files:
                fpath = output_path / fname
                if fpath.exists():
                    output_files.append(str(fpath))

            return {
                "command_executed": " ".join(cmd),
                "stdout": result.stdout,
                "stderr": result.stderr,
                "output_files": output_files,
                "success": True,
                "error": None,
            }

        except subprocess.CalledProcessError as e:
            return {
                "command_executed": " ".join(cmd),
                "stdout": e.stdout,
                "stderr": e.stderr,
                "output_files": [],
                "success": False,
                "error": f"AME motif enrichment failed with exit code {e.returncode}: {e.stderr}",
            }
        except subprocess.TimeoutExpired:
            return {
                "command_executed": " ".join(cmd),
                "stdout": "",
                "stderr": "",
                "output_files": [],
                "success": False,
                "error": "AME motif enrichment timed out after 1800 seconds",
            }

    @mcp_tool()
    def glam2scan_scanning(
        self,
        glam2_file: str,
        sequences: str,
        output_dir: str = "glam2scan_out",
        score: float = 0.0,
        norc: bool = False,
        verbosity: int = 1,
    ) -> dict[str, Any]:
        """
        Scan sequences with GLAM2 motifs using GLAM2SCAN.

        GLAM2SCAN searches for occurrences of GLAM2 motifs in sequences.

        Args:
            glam2_file: GLAM2 motif file
            sequences: Sequences file (FASTA format)
            output_dir: Output directory for results
            score: Score threshold for reporting matches
            norc: Don't search reverse complement strand
            verbosity: Verbosity level

        Returns:
            Dictionary containing command executed, stdout, stderr, output files, success, error
        """
        # Validate input files
        glam2_path = Path(glam2_file)
        seq_path = Path(sequences)
        if not glam2_path.exists():
            raise FileNotFoundError(f"GLAM2 file not found: {glam2_file}")
        if not seq_path.exists():
            raise FileNotFoundError(f"Sequences file not found: {sequences}")

        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Validate parameters
        if verbosity < 0:
            raise ValueError("verbosity must be >= 0")

        # Build command
        cmd = [
            "glam2scan",
            "-o",
            output_dir,
            "-score",
            str(score),
            "-verbosity",
            str(verbosity),
            glam2_file,
            sequences,
        ]

        if norc:
            cmd.append("-norc")

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                timeout=1800,  # 30 minutes timeout
            )

            # Check for expected output files
            output_files = []
            expected_files = [
                "glam2scan.txt",
                "glam2scan.xml",
            ]

            for fname in expected_files:
                fpath = output_path / fname
                if fpath.exists():
                    output_files.append(str(fpath))

            return {
                "command_executed": " ".join(cmd),
                "stdout": result.stdout,
                "stderr": result.stderr,
                "output_files": output_files,
                "success": True,
                "error": None,
            }

        except subprocess.CalledProcessError as e:
            return {
                "command_executed": " ".join(cmd),
                "stdout": e.stdout,
                "stderr": e.stderr,
                "output_files": [],
                "success": False,
                "error": f"GLAM2SCAN scanning failed with exit code {e.returncode}: {e.stderr}",
            }
        except subprocess.TimeoutExpired:
            return {
                "command_executed": " ".join(cmd),
                "stdout": "",
                "stderr": "",
                "output_files": [],
                "success": False,
                "error": "GLAM2SCAN scanning timed out after 1800 seconds",
            }

    async def deploy_with_testcontainers(self) -> MCPServerDeployment:
        """Deploy MEME server using testcontainers."""
        try:
            import asyncio

            from testcontainers.core.container import DockerContainer

            # Create container with MEME suite
            container = DockerContainer("condaforge/miniforge3:latest")
            container.with_name(f"mcp-meme-server-{id(self)}")

            # Install MEME suite
            install_cmd = """
            conda env update -f /tmp/environment.yaml && \
            conda clean -a && \
            mkdir -p /app/workspace /app/output && \
            echo 'MEME server ready'
            """

            # Copy environment file and install
            env_content = """name: mcp-meme-env
channels:
  - bioconda
  - conda-forge
dependencies:
  - meme
  - pip
"""

            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".yaml", delete=False
            ) as f:
                f.write(env_content)
                env_file = f.name

            container.with_volume_mapping(env_file, "/tmp/environment.yaml")
            container.with_command(f"bash -c '{install_cmd}'")

            # Start container
            container.start()

            # Wait for container to be ready
            container.reload()
            while container.status != "running":
                await asyncio.sleep(0.1)
                container.reload()

            # Store container info
            self.container_id = container.get_wrapped_container().id
            self.container_name = container.get_wrapped_container().name

            # Clean up temp file
            try:
                Path(env_file).unlink()
            except OSError:
                pass

            return MCPServerDeployment(
                server_name=self.name,
                server_type=self.server_type,
                container_id=self.container_id,
                container_name=self.container_name,
                status=MCPServerStatus.RUNNING,
                tools_available=self.list_tools(),
                configuration=self.config,
            )

        except Exception as e:
            return MCPServerDeployment(
                server_name=self.name,
                server_type=self.server_type,
                status=MCPServerStatus.FAILED,
                error_message=f"Failed to deploy MEME server: {e}",
                configuration=self.config,
            )

    async def stop_with_testcontainers(self) -> bool:
        """Stop MEME server testcontainer."""
        try:
            if self.container_id:
                from testcontainers.core.container import DockerContainer

                # Find and stop container
                container = DockerContainer("condaforge/miniforge3:latest")
                container.with_name(self.container_name)
                container.stop()

                self.container_id = None
                self.container_name = None
                return True
            return False
        except Exception:
            return False
